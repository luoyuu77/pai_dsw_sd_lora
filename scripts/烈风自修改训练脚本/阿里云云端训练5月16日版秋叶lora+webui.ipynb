{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2803e4-2982-4e13-be9f-f5654ae4607b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 作者的话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb452fdd-ab97-438a-abc6-94c7efdb4a96",
   "metadata": {},
   "source": [
    ">我一开始做这个呢，是看了秋叶的阿里云视频，然后突发奇想，想要自己进行lora训练，结果怎么着也不行，而到目前为止也没有比较好的训练教程出现。\n",
    "\n",
    ">于是万般无果之下，我开始了疯狂的学习，经过了多次讨论和指导之后，我在低级镜像的基础上完成了简化版lora的制作也就是上个视频，但是效果呢不尽如人意，于是乎我决定重新制作，从镜像做起，在经过几天几夜的学习后我成功掌握了镜像，\n",
    "\n",
    "> 但是这个时候，我突然发现了一个问题，那就是我没有可以和a10或v100与之相配的显卡，那么我要如何制作镜像呢，而在我万念俱灰之下，我发现了阿里云能免费租用服务器，\n",
    "\n",
    ">于是我租用了阿里云的服务器，准备安装docker，而这个时候docker安装好了，其他依赖也已经做好了，这个时候我发现，我租的服务器连显卡都没有根本装不上驱动，\n",
    "\n",
    ">所以又失败了，这个时候我又想着，那么我能不能再机器学习里进行docker的镜像训练呢，又经过了几天几夜的尝试，终于我失败了，运行机器学习的本身便是docker，\n",
    "\n",
    ">我怎么可能在docker里再安装一个docker呢。镜像这条路到这里便已经算是彻底失败了，但是我不甘心，我开始利用秋叶给的镜像翻来复去的测试，而最后我将全部可能出现的问题都解决了，\n",
    "\n",
    ">终于完成了这个最终版，历时近一个月。\n",
    "\n",
    ">作为一个单纯有些编程基础的我来说可以说是不容易，而在这里也感谢支持我的粉丝，和给予我代码指导的大佬们，如果大家喜欢还请给我点点关注一键三连。https://space.bilibili.com/1299813918"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d2e84-e8a7-4f95-b323-3525e28775e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **基于Bilibili UP主：[秋葉aaaki]发布的[保姆式LoRA模型一键包文件](https://www.bilibili.com/video/BV1fs4y1x7p2/)和WSH032大佬于colab的依赖代码修改而来。**\n",
    "最核心的文件的整合与代码均由主要作者[秋葉aaaki](https://github.com/Akegarasu/lora-scripts)和WSH032完成。\n",
    "开始前**建议阅读**：\n",
    "1.   [保姆式LoRA模型一键包文件](https://www.bilibili.com/video/BV1fs4y1x7p2/)\n",
    "2.   [参数心得](https://www.bilibili.com/video/BV1GM411E7vk/)\n",
    "3.   [训练教程](https://www.bilibili.com/read/cv21926598)\n",
    "4.   [阿里云部署教程](https://www.bilibili.com/video/BV1po4y1877P/?vd_source=e6294619bd5137ea0025a3d001e715a7#reply161206731712)\n",
    "> 本人只是完成阿里云下的依赖安装，使用的下载源不保证长期有效。本人对python与linux的使用能力有限，代码在各位大佬的指导下完成，不足部分，有兴趣者可修改并分享。\n",
    "\n",
    "> *--分享的责任与获取的自由*\n",
    "**待解决问题**:\n",
    "\n",
    "> 1.如何在阿里云的jupyter添加交互式滑块功能呢？\n",
    "\n",
    "\n",
    "> 2.关于数据集的挂载，我这边没有相应教程如有需要可自行解决\n",
    "\n",
    "    \n",
    "常见问题：\n",
    "1.   Q：输出代码的最后出现*（kill:9）*字样\n",
    "\n",
    "    A：爆ram了，更换小的底模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43a5be-b083-47ee-bdb2-28c85d25c784",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 一、安装基础依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4310c11-c5c5-4727-9b8b-8b5145c659ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#进行全局加速\n",
    "!git config --global url.\"https://ghproxy.com/https://github.com\".insteadOf \"https://github.com\"\n",
    "#查看是什么GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25936d7-e342-4769-95e2-6f8c4ce8cccc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#安装解压软件和下载存储工具\n",
    "!apt-get update  > /dev/null 2>&1 \n",
    "!apt-get install zip -y > /dev/null 2>&1\n",
    "!apt install -y aria2 > /dev/null 2>&1\n",
    "#安装依赖\n",
    "!pip -q install torch==2.0.0 torchvision xformers triton    \n",
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "import triton\n",
    "print(torch.__version__)#2.0.0+cu117 \n",
    "print(torchvision.__version__)  #0.15.1+cu117\n",
    "print(transformers.__version__)   #4.25.1\n",
    "print(triton.__version__)  # 2.0.0\n",
    "#如输出的版本与注释相对应则代表安装成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efd9ef-2d21-4259-9d00-dd9b77e7c381",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 二、加载训练包（将加载2023年4月29日的秋叶最新训练包）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6aa63-0994-493a-a799-909c751a65a7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd  /mnt/workspace/\n",
    "!git clone -b v5.16  https://ghproxy.com/https://github.com/taiczhi/lora-scripts.git\n",
    "!cd /mnt/workspace/lora-scripts/huggingface/ && wget -c https://liblibai-online.vibrou.com/web/model/c52a9848ee316e16b59a0fe17e17edc4c767f97f652b439d9da758d6077160ae.ckpt  -O 1.zip\n",
    "!unzip /mnt/workspace/lora-scripts/huggingface/1.zip -d /mnt/workspace/lora-scripts/huggingface/ > /dev/null 2>&1 && echo 解压成功\n",
    "!sudo rm -r /mnt/workspace/lora-scripts/huggingface/1.zip   > /dev/null 2>&1  && echo 删除压缩包成功\n",
    "!mkdir -p /mnt/workspace/lora-scripts/train/aki\n",
    "!mkdir -p /mnt/workspace/lora-scripts/train/reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f8589-ff65-4601-b8f0-27764243d6af",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  三、进行正则参数的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa868b4f-f307-4b65-926e-bb3db72f5fa3",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-05-14T07:43:00.520493Z",
     "iopub.status.busy": "2023-05-14T07:43:00.520119Z",
     "iopub.status.idle": "2023-05-14T07:43:00.691865Z",
     "shell.execute_reply": "2023-05-14T07:43:00.691143Z",
     "shell.execute_reply.started": "2023-05-14T07:43:00.520471Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#创建目录\n",
    "!mkdir -p /mnt/workspace/drive/MyDrive/Lora/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc34b25-957b-466a-9b34-b18667ada33d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#定义正则表达式函数、声明ExtArgsContent类用于修改extArgs的值、初始化output、log、sample_prompt.txt、训练材料路径（必须运行）\n",
    "#这是一个使用正则表达式匹配编辑文件的函数，用于对train.sh的修改\n",
    "#导入正则表达式模块\n",
    "import re\n",
    "#########\n",
    "#设置train.sh文件路径，这个在函数中会被使用\n",
    "train_sh_path = r'/mnt/workspace/lora-scripts/train.sh'\n",
    "#########\n",
    "#定义函数，编辑train_sh_path路径的文件，为search的参数赋予值input\n",
    "#search为字符串，input可以为数值和字符串\n",
    "def search_input(search, input):\n",
    "  # 使用正则表达式进行替换\n",
    "  #匹配标志: 1匹配search=\"\" ， 2匹配search=5 ， 3专门专门匹配extArgs=()\n",
    "  search_type_flag = 0\n",
    "\n",
    "  #search不是字符串就报错\n",
    "  if not( isinstance(search, str) ):\n",
    "    return \"非字符串的'search'参数\"\n",
    "\n",
    "  #如果search输入的是\"\"，则专门匹配extArgs=()\n",
    "  if search == \"\":\n",
    "    search = \"extArgs\"\n",
    "    pattern = rf'^{search}=(\\(.*?\\))'\n",
    "    replace = rf'{search}=({input})'\n",
    "    search_type_flag = 3\n",
    "  else:\n",
    "    # 如果input是字符串类型，匹配search=\"\"\n",
    "    if isinstance(input, str):\n",
    "      #pattern = rf'{search}=(\".*?\")'\n",
    "      #replace = f\"{search}=\\\"{input}\\\"\"\n",
    "      pattern = rf'^{search}=(\".*?\")'\n",
    "      replace = rf'{search}=\"{input}\"'\n",
    "      search_type_flag = 1\n",
    "    # 如果input是数值类型，匹配search= （可以匹配小数、整数、科学计数）\n",
    "    elif isinstance(input, (int, float)):\n",
    "      pattern = rf'^{search}=([+-]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][+-]?\\d+)?)'\n",
    "      replace = rf'{search}={input}'\n",
    "      search_type_flag = 2\n",
    "    else: # 其他情况，就返回错误信息 \n",
    "      return \"错误的匹配input\"\n",
    "\n",
    "  #使用with语句打开文件，并读取内容\n",
    "  with open(train_sh_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    re_get = re.findall(pattern, content, flags=re.MULTILINE|re.DOTALL)\n",
    "    #检查是否匹配到，匹配不到则报错并退出\n",
    "    if not(re_get):\n",
    "      print(f\"警告！！！对于'{search}'的正则表达式并未匹配，请手动设置该参数，并B站私信我更新！\")\n",
    "      return\n",
    "    #如果匹配到了执行接下来操作\n",
    "    #使用re.sub函数进行替换，并加上re.MULTILINE标志\n",
    "    new_content = re.sub(pattern, replace, content, flags=re.MULTILINE|re.DOTALL, count=1)\n",
    "    #如果内容未更改，提示未改变以及值\n",
    "    if new_content == content:\n",
    "      print(f\"{search}={re_get[0]}\")\n",
    "      return\n",
    "    #如果改变则写入，输出改变信息\n",
    "    else:\n",
    "      with open(train_sh_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(new_content)\n",
    "      if search_type_flag == 1: right = left = \"\\\"\"\n",
    "      elif search_type_flag == 2: right = left = \"\"\n",
    "      elif search_type_flag == 3: right = \")\" ; left = \"(\" \n",
    "      else: print(\"输入参数错误\")\n",
    "      print(f\"发生修改，{search}={re_get[0]}现在为{left}{input}{right}\")\n",
    "\n",
    "#模型输出地址被更改至\"drive/MyDrive/Lora/output/\" \n",
    "output_dir = \"/mnt/workspace/drive/MyDrive/Lora/output/\"\n",
    "search_input(\"  --output_dir\", output_dir)\n",
    "print(f\"模型输出地址默认被更改至：{output_dir}\")\n",
    "\n",
    "#初始化log输出路径\n",
    "logging_dir = output_dir + \"/logs\"\n",
    "search_input(\"  --logging_dir\", logging_dir)\n",
    "print(f\"log日志默认输出至：{logging_dir}\")\n",
    "\n",
    "#初始化sample_prompt.txt路径\n",
    "sample_prompt_txt_path = \"/mnt/workspace/lora-scripts/sample_prompt.txt\"\n",
    "print(f\"sample_prompt.txt默认路径为：{sample_prompt_txt_path}\")\n",
    "\n",
    "#初始化训练集路径\n",
    "train_data_dir = \"/mnt/workspace/lora-scripts/train/aki/\"\n",
    "search_input(\"train_data_dir\", train_data_dir)\n",
    "print(f\"训练集将拷贝至：{train_data_dir}\")\n",
    "\n",
    "#初始化正则化集路径\n",
    "reg_data_dir = \"/mnt/workspace/lora-scripts/train/reg/\"\n",
    "print(f\"正则化集将拷贝至：{reg_data_dir}\")\n",
    "#################################################################\n",
    "#声明extArgs_Content类，用于在不同代码块中更新extArgs的内容\n",
    "class ExtArgsContent(object):\n",
    "  def __init__(self):\n",
    "    self.base_model = \"\"\n",
    "    self.vae = \"\"\n",
    "    self.common_parameter = \"\"\n",
    "    self.sample_parameter = \"\"\n",
    "    self.plus_parameter = \"\"\n",
    "  #合并全部类属性字符串\n",
    "  def all(self):\n",
    "    result = \"\"\n",
    "    attributes = self.__dict__.values()\n",
    "    for attribute in attributes:\n",
    "      result += attribute\n",
    "    return result\n",
    "extArgs_content = ExtArgsContent()\n",
    "\n",
    "#################################################################\n",
    "#用于读取  --output_dir=\"\"和  --logging_dir=\"\"的值，来修改保存路径\n",
    "def search_get(search):\n",
    "  # 如果input是字符串类型，匹配search=\"\"\n",
    "  #pattern = rf'{search}=(\".*?\")'\n",
    "  pattern = rf'^{search}=(\".*?\")'\n",
    "  #使用with语句打开文件，并读取内容\n",
    "  with open(train_sh_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    re_get = re.findall(pattern, content, flags=re.MULTILINE|re.DOTALL)\n",
    "    return re_get[0]\n",
    "#################################################################\n",
    "enable_sample = False\n",
    "use_train_sh_self = False\n",
    "use_sample_prompt_txt_self = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7da61b-0a80-486a-a283-b2ae4e0caaa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 四、安装需求包依赖和训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42d094-f76e-4cfa-9ce8-a74c0874a467",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安装imjoy-elfinder（web文件浏览器）依赖\n",
    "!sudo apt-get update > /dev/null 2>&1 \n",
    "!sudo apt-get install -y python3-pip  > /dev/null 2>&1 \n",
    "!sudo apt-get install -y libfuse-dev  > /dev/null 2>&1 \n",
    "!pip3 install imjoy-elfinder         > /dev/null 2>&1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d4851-4e37-4240-a809-b0ad4be3ce9e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#进入目录\n",
    "%cd /mnt/workspace/lora-scripts/sd-scripts/\n",
    "#安装目录要求依赖\n",
    "!pip -q  install --upgrade -r requirements.txt && echo 安装需求依赖成功\n",
    "#安装训练指示器\n",
    "!pip -q install --upgrade lion-pytorch lycoris-lora dadaptation  && echo 安装训练器成功\n",
    "#进行bitsandbytes的重装\n",
    "!pip uninstall -q bitsandbytes -y > /dev/null 2>&1 && echo 卸载成功\n",
    "!pip install  -q --no-cache-dir bitsandbytes[full] > /dev/null 2>&1    && echo 安装成功\n",
    "#开启可视学习化曲线\n",
    "%load_ext tensorboard  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27bf8f-9742-4426-9bce-a34fa507bd12",
   "metadata": {
    "tags": []
   },
   "source": [
    " ## 五、下载并解压训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559fbeb-a6db-4e1d-b710-52f146e9e0df",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown 是否使用自定义路径，是否拷贝正则化图片\n",
    "use_data_dir_self = True #@param {type:\"boolean\"}\n",
    "copy_reg = False #@param {type:\"boolean\"}\n",
    "#@markdown 自定义训练集路径，正则化集路径（仅在勾选后有效）**（不要使用带空格、中文的路径）**\n",
    "train_data_dir_self = \"mnt/workspace/lora-scripts/train/aki\" #@param {type:'string'}\n",
    "reg_data_dir_self = \"mnt/workspace/lora-scripts/train/aki\" #@param {type:'string'}\n",
    "if copy_reg:\n",
    "  #拷贝正则化图片\n",
    "  print(f\"正则化集地址为:{reg_data_dir_self}\")\n",
    "  print(\"拷贝正则化集中\")\n",
    "  !mkdir -p {reg_data_dir}\n",
    "  !cp -r {reg_data_dir_self}/* {reg_data_dir}\n",
    "  !echo \"copy正则化图片完成.\"\n",
    "else:\n",
    "  print(\"不拷贝正则化集\")\n",
    "#下载训练集\n",
    "%cd /mnt/workspace/lora-scripts\n",
    "!mkdir -p /mnt/workspace/lora-scripts/train/  #防止首次运行报错删除文件夹\n",
    "!rm -r /mnt/workspace/lora-scripts/train/\n",
    "!mkdir -p /mnt/workspace/lora-scripts/train/aki\n",
    "! cd /mnt/workspace/lora-scripts/train/aki/ && wget -c  https://huggingface.co/d1111111/333/resolve/main/1.zip -O 1.zip > /dev/null 2>&1 && echo 下载成功\n",
    "#@markdown  model_url的位置是你训练集的上传链接你可以先传到https://huggingface.co/上然后到你上传文件的根目录复制其链接请注意链接如果出现中blob的路径请替换为resolve\n",
    "!unzip /mnt/workspace/lora-scripts/train/aki/1.zip -d /mnt/workspace/lora-scripts/train/aki/ > /dev/null 2>&1 && echo 解压成功\n",
    "!sudo rm -r /mnt/workspace/lora-scripts/train/aki/1.zip  > /dev/null 2>&1  && echo 删除压缩包成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feda212-7a52-4f4e-a574-d412b84c8c3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  六、如果你已经在本地完成了打标，那么请忽略这个代码块\n",
    "#        如果你没有打标那么可以试试这个效果据说不如webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34215c08-c2f9-45f1-ade0-716741df2048",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **是否使用WD1.4打标**\n",
    "use_tagger = True #@param {type:\"boolean\"}\n",
    "#@markdown **(必填)**填入你要打标的文件夹地址，如果你有多个概念文件夹，你需要为每个都执行这项操作\n",
    "tag_data_dir = \"/mnt/workspace/lora-scripts/train/aki/20_maqima\" #@param {type:'string'}\n",
    "#@markdown batch大小、加载线程、打标模型\n",
    "batch_size = 8 #@param {type:'number'}\n",
    "max_data_loader_n_workers = 2 #@param {type:'number'}\n",
    "tagger_model = \"SmilingWolf/wd-v1-4-convnext-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
    "#@markdown 调整阈值，越低tag越多，但准确率越低\n",
    "#@markdown - 这两句是代码作者的原话，请自行判断\n",
    "#@markdown - 高阈值(例如`0.85`)适用于人物或者物体的训练\n",
    "#@markdown - 低阈值(例如`0.35`)适用于常规的\\画风的\\环境的训练\n",
    "threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "if use_tagger:\n",
    "#图片路径的路径为下载数据集路径\n",
    "  !python /mnt/workspace/lora-scripts/sd-scripts/finetune/tag_images_by_wd14_tagger.py \\\n",
    "    \"{tag_data_dir}\" \\\n",
    "    --batch_size {batch_size} \\\n",
    "    --repo_id {tagger_model} \\\n",
    "    --thresh {threshold} \\\n",
    "    --caption_extension .txt \\\n",
    "    --max_data_loader_n_workers {max_data_loader_n_workers}\n",
    "else:\n",
    "  print(\"似乎你想使用WD1.4tagger，但你并未勾选\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ee618-e287-435d-b8be-fdc6f6ee0e8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##   七、下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71820a3-df25-4cf2-9fe7-4f0265f034ca",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "installModels = []\n",
    "installv2Models = []\n",
    "#@markdown ####**选择优先级从上到下，比如说你想自定义链接，则需要保持两个预设模型为空**\n",
    "#@markdown **预设剪枝模型（`Animefull-final-pruned`即NovelAI官模 ， `Stable-Diffusion-v1-5`即SD1.5）**\n",
    "#@markdown SD1.x model\n",
    "modelName = \"\"  # @param [\"\", \"Animefull-final-pruned\", \"Stable-Diffusion-v1-5\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\"]\n",
    "#@markdown SD2.x model\n",
    "v2ModelName = \"\"  # @param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"plat-diffusion-v1-3-1\", \"replicant-v1\", \"illuminati-diffusion-v1-0\", \"illuminati-diffusion-v1-1\", \"waifu-diffusion-1-4-anime-e2\", \"waifu-diffusion-1-5-e2\", \"waifu-diffusion-1-5-e2-aesthetic\"]\n",
    "\n",
    "#@markdown **自定义模型链接例如`https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt`）**\n",
    "\n",
    "#@markdown **或者自定义模型路径例如`/mnt/workspace/drive/MyDrive/Lora/model/your_model.ckpt`**\n",
    "\n",
    "#@markdown **如果连接或者路径中包含模型的扩展名(比如我给出的两个例如的末尾都有扩展名)，则会自动指定，否则你需要手动选择**\n",
    "\n",
    "base_model_url = \"https://liblibai-online.vibrou.com/models/e7e55f800035004cf0ee31d91f874a415a2b64a4.safetensors?attname=%E5%BF%85%E5%A4%87%E6%A8%A1%E5%9E%8B%EF%BD%9CChilloutMix_Chilloutmix-Ni-pruned-fp32-fix.safetensors\" #@param {type:\"string\"}\n",
    "\n",
    "base_model_self_dir = \"\" #@param {type:\"string\"}\n",
    "\n",
    "base_model_extension = \"safetensors\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
    "\n",
    "\n",
    "modelUrl = [\n",
    "    \"\",\n",
    "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
    "    \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
    "    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
    "    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
    "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
    "    \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
    "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
    "]\n",
    "modelList = [\n",
    "    \"\",\n",
    "    \"Animefull-final-pruned\",\n",
    "    \"Anything-v3-1\",\n",
    "    \"AnyLoRA\",\n",
    "    \"AnimePastelDream\",    \n",
    "    \"Chillout-mix\",\n",
    "    \"OpenJourney-v4\",\n",
    "    \"Stable-Diffusion-v1-5\",\n",
    "]\n",
    "v2ModelUrl = [\n",
    "    \"\",\n",
    "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
    "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
    "    \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
    "    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
    "    \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
    "    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
    "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
    "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
    "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
    "]\n",
    "v2ModelList = [\n",
    "    \"\",\n",
    "    \"stable-diffusion-2-1-base\",\n",
    "    \"stable-diffusion-2-1-768v\",\n",
    "    \"plat-diffusion-v1-3-1\",\n",
    "    \"replicant-v1\",\n",
    "    \"illuminati-diffusion-v1-0\",\n",
    "    \"illuminati-diffusion-v1-1\",\n",
    "    \"waifu-diffusion-1-4-anime-e2\",\n",
    "    \"waifu-diffusion-1-5-e2\",\n",
    "    \"waifu-diffusion-1-5-e2-aesthetic\",\n",
    "]\n",
    "if modelName:\n",
    "    installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
    "if v2ModelName:\n",
    "    installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
    "#下载路径\n",
    "base_model_dir = \"/mnt/workspace/lora-scripts/sd-models/\"\n",
    "\n",
    "#检查连接是否含有扩展名信息，不含有则由用户指定\n",
    "def check_ext(url):\n",
    "  if url.endswith(\".ckpt\"):\n",
    "    return \"ckpt\"\n",
    "  elif url.endswith(\".safetensors\"):\n",
    "    return \"safetensors\"\n",
    "  else:\n",
    "    return base_model_extension\n",
    "#下载模型\n",
    "def install(checkpoint_name, url):\n",
    "    ext = check_ext(url)\n",
    "    hf_token = \"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\"\n",
    "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
    "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {checkpoint_name}.{ext} {url}\n",
    "    return f\"{checkpoint_name}.{ext}\"   #返回模型名称\n",
    "def install_checkpoint():\n",
    "    for model in installModels:\n",
    "        return install(model[0], model[1])\n",
    "    for v2model in installv2Models:\n",
    "        return install(v2model[0], v2model[1])\n",
    "\n",
    "#尝试下载预设模型\n",
    "base_model_name = install_checkpoint()\n",
    "#预设下载成功，则完成路径修改\n",
    "if base_model_name:\n",
    "  pretrained_model = base_model_dir + base_model_name\n",
    "#下载失败，base_model_name为non\n",
    "else:\n",
    "  #不留空，则尝试用连接下载\n",
    "  if base_model_url:\n",
    "    base_model_name = \"download.\" + check_ext(base_model_url)\n",
    "    pretrained_model = base_model_dir + base_model_name\n",
    "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {base_model_name} --allow-overwrite {base_model_url}\n",
    "  #留空，将考虑从自定义路径中拷贝\n",
    "  else:\n",
    "    if base_model_self_dir:\n",
    "      base_model_name = \"self.\" + check_ext(base_model_self_dir)\n",
    "      pretrained_model = base_model_dir + base_model_name\n",
    "      !cp {base_model_self_dir} {pretrained_model}\n",
    "    else:\n",
    "      print(\"你根本没选择任何模型！\")\n",
    "#修改train.sh的底模路径，并输出信息\n",
    "search_input(\"pretrained_model\", pretrained_model)\n",
    "#输出模型信息\n",
    "print(f\"你选择的是: {base_model_name} 模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa5eaa-6a07-4225-a7e7-474bf756bbfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "##   VAE的使用非必选可跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a900b8-47cb-4059-b19a-3002009ba0ca",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "installVae = []\n",
    "#@markdown 选择 `none` 意味着不使用vae\n",
    "#@markdown 选择一个Vae下载并使用`\"animevae.pt\", \"kl-f8-anime.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\"`\n",
    "vaeUrl = [\n",
    "    \"\",\n",
    "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
    "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
    "    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
    "]\n",
    "vaeList = [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
    "vaeName = \"stablediffusion.vae.pt\"  # @param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
    "\n",
    "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
    "\n",
    "#开始下载\n",
    "vae_dir = \"/mnt/workspace/lora-scripts/vae/\"\n",
    "def install(vae_name, url):\n",
    "    hf_token = \"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\"\n",
    "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
    "    !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o \"vae.pt\" \"{url}\"\n",
    "\n",
    "def install_vae():\n",
    "    if vaeName != \"none\":\n",
    "        for vae in installVae:\n",
    "            install(vae[0], vae[1])\n",
    "    else:\n",
    "        pass\n",
    "install_vae()\n",
    "\n",
    "\n",
    "extArgs_content.vae = \"\"\n",
    "#修改train.sh中参数\n",
    "if vaeName == \"none\":\n",
    "  print(\"不使用vae\")\n",
    "else:\n",
    "  print(f\"使用{vaeName}\")\n",
    "  #写入采样地址f\"--vae={vae_dir}\"\n",
    "  extArgs_content.vae += f\"\\\"--vae={vae_dir}vae.pt\\\" \"\n",
    "\n",
    "search_input(\"\", extArgs_content.all() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894d09f-c44d-41b0-a750-f021e96ed9ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "##   八、设置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf81cd-71b3-4624-8bef-2b2d2d90e7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#用于修改train.sh文件\n",
    "extArgs_content.common_parameter = \"\"\n",
    "#底模信息\n",
    "#print(\"你选择的是\" + base_model + \"底模\")\n",
    "#print(\"格式为\" + base_model_extension)\n",
    "#@markdown 是否使用正则化、正则化权重（越小越不正则）\n",
    "use_reg_data = False #@param {type:\"boolean\"}\n",
    "if use_reg_data:\n",
    "  search_input(\"reg_data_dir\", \"reg_data_dir\")\n",
    "  print(\"\\b使用正则化\")\n",
    "else:\n",
    "  search_input(\"reg_data_dir\", \"\")\n",
    "  print(\"\\b不使用正则化\")\n",
    "prior_loss_weight = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "search_input(\"  --prior_loss_weight\", prior_loss_weight)\n",
    "#@markdown 输出模型命名、格式(模型会被输出至`{output_folder_dir}/{output_name}；)\n",
    "output_name = \"ling\" #@param {type:\"string\"}\n",
    "search_input(\"output_name\", output_name)\n",
    "save_model_as = \"safetensors\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
    "search_input(\"save_model_as\", save_model_as)\n",
    "output_folder_dir = \"/mnt/workspace/drive/MyDrive/Lora/ling\" #@param {type:\"string\"}\n",
    "#保存模型至同名文件夹\n",
    "output_dir = output_folder_dir + \"/\" + output_name\n",
    "search_input(\"  --output_dir\", output_dir)\n",
    "#修改log输出\n",
    "logging_dir = output_dir + \"/logs\"\n",
    "search_input(\"  --logging_dir\", logging_dir)\n",
    "print(f\"模型输出地址为：{output_dir}\")\n",
    "print(f\"log文件将会被保存至:{logging_dir}\")\n",
    "#@markdown 图片分辨率:\"宽,高\"。支持非正方形（必须是64的倍数）\n",
    "width = 768 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
    "height = 1024 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
    "resolution = f\"{width},{height}\"\n",
    "search_input(\"resolution\", resolution)\n",
    "#@markdown batch大小\n",
    "batch_size = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
    "search_input(\"batch_size\", batch_size)\n",
    "#@markdown 优化器选择 `一般用前三个就行\"`\n",
    "optimizer_type = \"AdamW8bit\" #@param [\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
    "search_input(\"optimizer_type\", optimizer_type)\n",
    "#@markdown unet学习率与text学习率（lr将被设置为等于unet_lr）\n",
    "#@markdown `DAdaptation优化器的学习率会自动调整，通常指定unet_lr=1;如果你希望text_encoder_lr为unet_lr一半，则指定text_encoder_lr=0.5`\n",
    "unet_lr = \"1.5e-4\" #@param {type:\"string\"}\n",
    "search_input(\"lr\", unet_lr)\n",
    "search_input(\"unet_lr\", unet_lr)\n",
    "text_encoder_lr = \"1e-5\" #@param {type:\"string\"}\n",
    "search_input(\"text_encoder_lr\", text_encoder_lr)\n",
    "#@markdown network dim与alpah\n",
    "network_dim = 64 #@param {type:\"number\"}\n",
    "search_input(\"network_dim\", network_dim)\n",
    "network_alpha = 32 #@param {type:\"number\"}\n",
    "search_input(\"network_alpha\", network_alpha)\n",
    "#@markdown 最大训练epoch ; 每N个epoch 保存一次\n",
    "max_train_epoches = 20 #@param {type:\"number\"}\n",
    "search_input(\"max_train_epoches\", max_train_epoches)\n",
    "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
    "search_input(\"save_every_n_epochs\", save_every_n_epochs)\n",
    "#@markdown 噪声偏移、保留前N个token顺序不变、伽马射线事件的最小信噪比`开启推荐为5`\n",
    "noise_offset = 0 #@param {type:\"number\"}\n",
    "search_input(\"noise_offset\", f\"{noise_offset}\")\n",
    "keep_tokens = 1 #@param {type:\"number\"}\n",
    "search_input(\"keep_tokens\", keep_tokens)\n",
    "min_snr_gamma = 0 #@param {type:\"number\"}\n",
    "search_input(\"min_snr_gamma\", min_snr_gamma)\n",
    "#@markdown 学习率调度器、升温步数、余弦硬重启次数 ； 升温步数建议设置成总steps的5%左右`总steps = epoch * repeat * (训练集+正则图数） / batch`不会算就跑一遍训练看看\n",
    "lr_scheduler = \"cosine_with_restarts\" #@param [\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"]\n",
    "search_input(\"lr_scheduler\", lr_scheduler)\n",
    "lr_warmup_steps = 0 #@param {type:\"number\"}\n",
    "search_input(\"lr_warmup_steps\", lr_warmup_steps)\n",
    "lr_restart_cycles = 1 #@param {type:\"number\"}\n",
    "search_input(\"lr_restart_cycles\", lr_restart_cycles)\n",
    "\n",
    "#@markdown 训练方法`\"LoRa\", \"LoCon\", \"LoHa\"`\n",
    "train_method = \"LoRa\" #@param [\"LoRa\", \"LoCon\", \"LoHa\"]\n",
    "if train_method == \"LoRa\":\n",
    "  network_module = \"networks.lora\"\n",
    "  algo = \"lora\"\n",
    "elif train_method == \"LoCon\":\n",
    "  network_module = \"lycoris.kohya\"\n",
    "  algo = \"lora\"\n",
    "elif train_method == \"LoHa\":\n",
    "  network_module = \"lycoris.kohya\"\n",
    "  algo = \"loha\"\n",
    "else:\n",
    "  print(\"训练方法选择出错\")\n",
    "search_input(\"network_module\", network_module)\n",
    "search_input(\"algo\", algo)\n",
    "print(f\"{train_method}训练方法\")\n",
    "  \n",
    "#@markdown locon训练的dim与alpha（仅在\"LoCon\"、\"LoHa\"训练方法时有效）\n",
    "conv_dim = 8 #@param {type:\"number\"}\n",
    "search_input(\"conv_dim\", conv_dim)\n",
    "conv_alpha = 4 #@param {type:\"number\"}\n",
    "search_input(\"conv_alpha\", conv_alpha)\n",
    "\n",
    "#@markdown 对于SD2模型(这个是底模为SD2训练时候使用的，不懂就不要选)\n",
    "is_v2_model = False #@param {type:\"boolean\"}\n",
    "search_input(\"is_v2_model\", 1 if is_v2_model else 0)\n",
    "parameterization = False #@param {type:\"boolean\"}\n",
    "search_input(\"parameterization\", 1 if parameterization else 0)\n",
    "\n",
    "if is_v2_model:\n",
    "  print(\"启动SD2.0模型设置\")\n",
    "if parameterization:\n",
    "  print(\"启动parameterization参数化\")\n",
    "\n",
    "\n",
    "#@markdown lowram模式(用显存来补充内存)\n",
    "lowram = False #@param {type:\"boolean\"}\n",
    "if lowram:\n",
    "  #写入\"--lowram\" \n",
    "  extArgs_content.common_parameter += \"\\\"--lowram\\\" \"\n",
    "  print(\"启动--lowram\")\n",
    "search_input(\"\", extArgs_content.all() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13629e-a756-4f1f-9e38-50190ed91c25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 九、进行边训练边出图的功能(可选)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4c0f0-6f6a-48b4-8636-79cf4fd55e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title ####采样图片参数设置,输出图片位置与模型输出文件夹一致\n",
    "#@markdown 支持使用`(1girl:1.1)`和`[1girl]`格式，不限数量的tag\n",
    "#@markdown 你要是懂怎么用，你也可以运行后修改这个采样参数文件`lora-scripts/sample_prompt.txt`\n",
    "#用于修改train.sh中extArgs数组的内容\n",
    "extArgs_content.sample_parameter = \"\"\n",
    "enable_sample = True #@param {type:\"boolean\"}\n",
    "#@markdown 采样间隔（每n个step/epoch采样，n=）\n",
    "sample_every_n_type = \"sample_every_n_epochs\" #@param [\"sample_every_n_steps\", \"sample_every_n_epochs\"]\n",
    "sample_every_n_type_value = 1 #@param {type:\"number\"}\n",
    "#@markdown 采样参数（采样器、正面tag、负面、宽、高、scale、种子、采样步数）\n",
    "sampler = \"dpmsolver++\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
    "prompt = \"(masterpiece, best quality, hi-res:1.2), 1girl, solo\" #@param {type: \"string\"}\n",
    "negative = \"(worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type:\"string\"}\n",
    "width = 768 #@param {type:\"number\"}\n",
    "height = 1024 #@param {type:\"number\"}\n",
    "scale = 7 #@param {type:\"number\"}\n",
    "seed = -1 #@param {type:\"number\"}\n",
    "steps = 20 #@param {type:\"number\"}\n",
    "#配置采样参数\n",
    "sample_str = f\"\"\"\n",
    "  {prompt} \\\n",
    "  --n {negative} \\\n",
    "  --w {width} \\\n",
    "  --h {height} \\\n",
    "  --l {scale} \\\n",
    "  --s {steps} \\\n",
    "  {f\"--d \" + f\"{seed}\" if seed > 0 else \"\"} \\\n",
    "\"\"\"\n",
    "\n",
    "if enable_sample:\n",
    "  #生成采样参数文件\n",
    "  with open(sample_prompt_txt_path, \"w\") as f:\n",
    "    f.write(sample_str)\n",
    "  #写入采样地址\"--sample_prompts={sample_prompt_txt_path}\"\n",
    "  extArgs_content.sample_parameter += f\"\\\"--sample_prompts={sample_prompt_txt_path}\\\" \"\n",
    "  #\"--sample_sampler=euler_a\"\n",
    "  extArgs_content.sample_parameter += f\"\\\"--sample_sampler={sampler}\\\" \"\n",
    "  #写入采样间隔\"--sample_every_n_epochs=1\"\n",
    "  if sample_every_n_type == \"sample_every_n_epochs\":\n",
    "    extArgs_content.sample_parameter += f\"\\\"--sample_every_n_epochs={sample_every_n_type_value}\\\" \"\n",
    "  elif sample_every_n_type == \"sample_every_n_steps\":\n",
    "    extArgs_content.sample_parameter += f\"\\\"--sample_every_n_steps={sample_every_n_type_value}\\\" \"\n",
    "  else:\n",
    "    print(\"采样间隔参数出错\")\n",
    "  print(f\"启用采样功能\")\n",
    "else:\n",
    "  print(f\"不使用采样功能\")\n",
    "#写入trian.sh\n",
    "search_input(\"\", extArgs_content.all() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444bd6b-1c45-4a80-9d99-0f1e7b658576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## loss与学习率可视化工具(可选）大概率报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48263cba-9413-4847-99e3-f1f0d8fb670e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown 你可以在训练前启动它，当训练开始过一会出现loss后，右上角刷新就可以实时监控loss和学习率 ； 训练开始后，如果你没启动的话，就只能在训练**结束**后启动\n",
    "use_tensorboard = True #@param {type:\"boolean\"}\n",
    "#@markdown 是否使用自定义的log日志路径:`留空则指定为当前train.sh中指定的log日志路径`\n",
    "logging_dir_self = \"\" #@param {type:\"string\"}\n",
    "#@markdown 如果提示端口被占用，就换个端口\n",
    "port = \"8008\" #@param {type:\"string\"}\n",
    "if use_tensorboard:\n",
    "  #指定tensorboard的读取路径\n",
    "  if logging_dir_self:\n",
    "    tensorboard_log_dir = logging_dir_self\n",
    "    print(f\"你指定了自定义的log日志路径：{tensorboard_log_dir}\")\n",
    "  else:\n",
    "    tensorboard_log_dir = search_get(\"  --logging_dir\")\n",
    "    print(f\"采用trian.sh中指定的log日志路径：{tensorboard_log_dir}\")\n",
    "  %tensorboard --logdir={tensorboard_log_dir} --port={port}\n",
    "else:\n",
    "  print(\"你似乎想使用tensorboard，但并未勾选该选项\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff48102-3937-4681-a5a3-e7e8a50b0445",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 十、开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a02620-4e79-499a-90c7-942c2b25ce34",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown 若正确运行，训练完成后，模型会自动保存`\n",
    "#@markdown 如果不到1分钟就运行完了，多半是出错了，把输出信息复制到ChatGPT问下罢！ :(\n",
    "#@markdown - Q：输出代码的最后出现（kill:9）字样 \n",
    "#@markdown - A：爆ram了，更换小的底模\n",
    "#@markdown ---\n",
    "#@markdown 是否保存本次训练的train.sh和采样配置（如果你启用采样功能的话）\n",
    "#@markdown 保存路径： `留空则保存至当前train.sh中指定的输出路径`\n",
    "save_files = True #@param {type:\"boolean\"}\n",
    "save_files_dir_self = \"\" #@param {type:\"string\"}\n",
    "if save_files:\n",
    "  #指定保存路径\n",
    "  if save_files_dir_self:\n",
    "    save_files_dir = save_files_dir_self\n",
    "    print(f\"你指定了自定义的配置保存路径：{save_files_dir}\")\n",
    "  else:\n",
    "    save_files_dir = search_get(\"  --output_dir\")\n",
    "    print(f\"采用trian.sh中指定的输出路径：{save_files_dir}\")\n",
    "  #保存训练参数文件\n",
    "  !mkdir -p {save_files_dir}\n",
    "  !cp {train_sh_path} {save_files_dir}\n",
    "  print(f\"训练参数被保存至{save_files_dir}\")\n",
    "  #保存采样参数文件\n",
    "  if enable_sample or use_sample_prompt_txt_self:\n",
    "    !cp {sample_prompt_txt_path} {save_files_dir}\n",
    "    print(f\"采样参数被保存至{save_files_dir}\")\n",
    "  else:\n",
    "    print(f\"未启用采样功能，不保存采样配置\")\n",
    "else:\n",
    "  print(f\"不保存配置文件\")\n",
    "\n",
    "#开始训练！\n",
    "%cd /mnt/workspace/lora-scripts/\n",
    "!bash train.sh\n",
    "\n",
    "!echo \"完成了 XXXD.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295cbd5-994a-498f-bb95-28ea9b9ae1f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 十一、进一步进行训练(我没用过不知道能不能行如果可以告诉我)(可选非必要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53227e96-ef73-490c-a0c5-6b6f9cd2b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ####设置进阶参数\n",
    "#用于暂存要修改至extArgs的内容\n",
    "extArgs_content.plus_parameter = \"\"\n",
    "#@markdown 从训练好的lora模型上继续训练，填写模型地址，如`drive/MyDrive/Lora/output/output_name.safetensors`,留空则不启用该功能\n",
    "\n",
    "#@markdown 从学习状态上继续训练，填写学习状态文件夹地址，如`drive/MyDrive/Lora/output/ouput_name-n-state`,留空我不知道会怎么样\n",
    "use_retrain = \"model\" #@param [\"no\",\"model\",\"state\"]\n",
    "retrain_dir = \"/mnt/workspace/drive/MyDrive/Lora/output\" #@param {type:\"string\"}\n",
    "\n",
    "if use_retrain == \"no\":\n",
    "  search_input(\"network_weights\", \"\")\n",
    "  search_input(\"resume\", \"\")\n",
    "  print(\"不使用重训练\")\n",
    "elif use_retrain == \"model\":\n",
    "  search_input(\"network_weights\", retrain_dir)\n",
    "  search_input(\"resume\", \"\")\n",
    "  print(\"从预先训练的lora模型上继续训练\")\n",
    "elif use_retrain == \"state\":\n",
    "  search_input(\"network_weights\", \"\")\n",
    "  search_input(\"resume\", retrain_dir)\n",
    "  print(\"从上次的学习状态继续训练\")\n",
    "#@markdown 保存epoch模型的同时保存学习状态（包括优化器状态，tensorboard查看）,方便更加精确的断点训练，**注意每个状态文件夹有5g**，建议高repeat低epoch长时间训练时使用\n",
    "save_state = True #@param {type:\"boolean\"}\n",
    "search_input(\"save_state\", 1 if save_state else 0)\n",
    "print( (\"\"if save_state else \"不\") + \"保存学习状态\")\n",
    "\n",
    "#@markdown 桶最小、大分辨率\n",
    "min_bucket_reso = 256 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
    "search_input(\"min_bucket_reso\", min_bucket_reso)\n",
    "max_bucket_reso = 1024 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
    "search_input(\"max_bucket_reso\", max_bucket_reso)\n",
    "#@markdown 跳过层\n",
    "clip_skip = 2 #@param {type:\"slider\", min:1, max:2, step:1}\n",
    "search_input(\"clip_skip\", clip_skip)\n",
    "#@markdown 标签文件扩展名\n",
    "caption_extension = \"txt\" #@param {type:\"string\"}\n",
    "caption_extension = \".\" + caption_extension\n",
    "search_input(\"  --caption_extension\", caption_extension)\n",
    "\n",
    "#@markdown 训练最大token数\n",
    "max_token_length = 225 #@param {type:\"slider\", min:75, max:225, step:75}\n",
    "search_input(\"  --max_token_length\", max_token_length)\n",
    "\n",
    "\n",
    "#@markdown 种子\n",
    "seed = \"1337\" #@param {type:\"string\"}\n",
    "search_input(\"  --seed\", seed)\n",
    "\n",
    "\n",
    "#写入train.sh\n",
    "search_input(\"\", extArgs_content.all() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
